{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": [
    "# Informer Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5GFng7v7Eq0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# if not 'Informer2020' in sys.path:\n",
    "#     sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPdt-Kwc_RRZ"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.ipynb_helpers import args_from_setting, setting_from_args, handle_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mx2dnwY9dWi"
   },
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'custom' # data\n",
    "args.root_path = './data/ETT/' # root path of data file\n",
    "\n",
    "\n",
    "args.data_path = 'close_pct_change.csv' # data file\n",
    "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'XOM_close' # target feature in S or MS task\n",
    "args.freq = 't' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 256 # input sequence length of Informer encoder\n",
    "args.label_len = 64 # start token length of Informer decoder\n",
    "args.pred_len = 16 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 1#13 # encoder input size\n",
    "args.dec_in = 1#13 # decoder input size\n",
    "args.c_out = 1 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in encoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "\n",
    "args.batch_size = 32 \n",
    "args.learning_rate = 0.00001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1 # number of runs\n",
    "args.train_epochs = 10\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.scale = True # True\n",
    "args.inverse = False # True # Defaultly False but @Zac thinks it should be True\n",
    "\n",
    "\n",
    "args.cols = [\"XOM_close\"]\n",
    "args.date_cutoff = None # \"2021-01-01\"\n",
    "args.date_test = \"2022-04-01\" # None\n",
    "\n",
    "handle_gpu(args, None)\n",
    "\n",
    "# idk what this is for\n",
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test *args.itr* models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928tzaA2AA2g",
    "outputId": "c19f673a-02d1-4f4d-91c3-d0f25e600443"
   },
   "outputs": [],
   "source": [
    "exp = None\n",
    "setting = None\n",
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = setting_from_args(args, ii)\n",
    "    \n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDHF-HerAE3u"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTkluNNcyMJt",
    "outputId": "780767fe-6321-4081-e827-6701daeb375b"
   },
   "outputs": [],
   "source": [
    "# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n",
    "# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n",
    "# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n",
    "\n",
    "# args = dotdict(model='informer', data='WTH', root_path='./data/ETT/', data_path='WTH.csv', features='M', target='WetBulbCelsius', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=24, enc_in=12, dec_in=12, c_out=12, d_model=512, n_heads=8, e_layers=2, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=2, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
    "\n",
    "manual = False\n",
    "\n",
    "if manual:\n",
    "    setting = \"informer_custom_ftMS_sl256_ll64_pl16_ei1_di1_co1_iFalse_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0\"\n",
    "    args = args_from_setting(setting, args)\n",
    "\n",
    "    exp = Exp(args)\n",
    "\n",
    "path = os.path.join(args.checkpoints, setting, \"checkpoint.pth\")\n",
    "\n",
    "exp.predict(setting, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBCPbjGuzAZb",
    "outputId": "945dc447-88e8-4b08-b7e5-f0a0b486d138"
   },
   "outputs": [],
   "source": [
    "# the prediction will be saved in ./results/{setting}/real_prediction.npy\n",
    "\n",
    "prediction = np.load(f\"./results/{setting}/real_prediction.npy\")\n",
    "\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yFuVkTV30_j"
   },
   "source": [
    "### More details about Prediction - prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sv9AR_Aw030r"
   },
   "outputs": [],
   "source": [
    "# here is the detailed code of function predict\n",
    "\n",
    "def predict(exp, setting, load=False):\n",
    "    pred_data, pred_loader = exp._get_data(flag='pred')\n",
    "        \n",
    "    if load:\n",
    "        path = os.path.join(exp.args.checkpoints, setting)\n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        exp.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    exp.model.eval()\n",
    "        \n",
    "    preds = []\n",
    "        \n",
    "    for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "        batch_x = batch_x.float().to(exp.device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "        # decoder input\n",
    "        if exp.args.padding==0:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        elif exp.args.padding==1:\n",
    "            dec_inp = torch.ones([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        else:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        dec_inp = torch.cat([batch_y[:,:exp.args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "        # encoder - decoder\n",
    "        if exp.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if exp.args.output_attention:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if exp.args.output_attention:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        f_dim = -1 if exp.args.features=='MS' else 0\n",
    "        batch_y = batch_y[:,-exp.args.pred_len:,f_dim:].to(exp.device)\n",
    "        \n",
    "        pred = outputs.detach().cpu().numpy()#.squeeze()\n",
    "        \n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    \n",
    "    # result save\n",
    "    folder_path = './results/' + setting +'/'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    np.save(folder_path+'real_prediction.npy', preds)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVLWZL2a1pwB",
    "outputId": "421e9ae1-f024-42b6-c8cb-ed1d38c864cd"
   },
   "outputs": [],
   "source": [
    "# you can also use this prediction function to get result\n",
    "prediction = predict(exp, setting, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "NwtZmQC71uc8",
    "outputId": "eec9d116-f122-42d9-8e02-c893ff764db0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(prediction[0,:,-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnePVyrW4I14"
   },
   "source": [
    "### More details about Prediction - prediction dataset\n",
    "\n",
    "You can give a `root_path` and `data_path` of the data you want to forecast, and set `seq_len`, `label_len`, `pred_len` and other arguments as other Dataset. The difference is that you can set a more detailed freq such as `15min` or `3h` to generate the timestamp of prediction series.\n",
    "\n",
    "`Dataset_Pred` only has one sample (including `encoder_input: [1, seq_len, dim]`, `decoder_token: [1, label_len, dim]`, `encoder_input_timestamp: [1, seq_len, date_dim]`, `decoder_input_timstamp: [1, label_len+pred_len, date_dim]`). It will intercept the last sequence of the given data (seq_len data) to forecast the unseen future sequence (pred_len data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZpXhNGp34Hf4"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import Dataset_Pred\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4Rpd1q74T8N"
   },
   "outputs": [],
   "source": [
    "Data = Dataset_Pred\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'pred'; shuffle_flag = False; drop_last = False; batch_size = 1\n",
    "\n",
    "freq = args.detail_freq\n",
    "\n",
    "data_set = Data(args, flag=flag, freq=freq, timeenc=timeenc)\n",
    "#     root_path=args.root_path,\n",
    "#     data_path=args.data_path,\n",
    "#     flag=flag,\n",
    "#     size=[args.seq_len, args.label_len, args.pred_len],\n",
    "#     features=args.features,\n",
    "#     target=args.target,\n",
    "#     timeenc=timeenc,\n",
    "#     freq=freq,\n",
    "\n",
    "#     inverse=args.inverse,\n",
    "#     cols=args.cols\n",
    "# )\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42C84BfY6UPV",
    "outputId": "f5ccc428-db92-4708-e104-f5d29aa5adf9"
   },
   "outputs": [],
   "source": [
    "len(data_set), len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNhEP_7sAgqC"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMRk8VkQ2Iko",
    "outputId": "bbf3cd10-7294-472d-e330-21e00f20963a"
   },
   "outputs": [],
   "source": [
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "preds = np.load(f\"./results/{setting}/pred.npy\")\n",
    "trues = np.load(f\"./results/{setting}/true.npy\")\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "preds.shape, trues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEGhDOmxAeAb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "kyPuOPGAAjl3",
    "outputId": "8554f6f8-c13a-43e1-b04b-5f27823445d0"
   },
   "outputs": [],
   "source": [
    "# draw OT prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[0,:,-1], label='GroundTruth')\n",
    "plt.plot(preds[0,:,-1], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "43MIgWfpMYIB",
    "outputId": "327f64b7-363c-44f9-c7c8-1f654911068c"
   },
   "outputs": [],
   "source": [
    "# draw HUFL prediction\n",
    "plt.figure()\n",
    "plt.plot(trues[0,:,0], label='GroundTruth')\n",
    "plt.plot(preds[0,:,0], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKmqhCfmt0xd"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import Dataset_Custom\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Data = Dataset_Custom\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
    "data_set = Data(args, flag=flag, freq=freq, timeenc=timeenc)\n",
    "    # root_path=args.root_path,\n",
    "    # data_path=args.data_path,\n",
    "    # flag=flag,\n",
    "    # size=[args.seq_len, args.label_len, args.pred_len],\n",
    "    # features=args.features,\n",
    "    # timeenc=timeenc,\n",
    "    # freq=args.freq,\n",
    "\n",
    "    # target=args.target,\n",
    "    # inverse=args.inverse,\n",
    "    # cols=args.cols\n",
    "# )\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iflTTl0quCoK",
    "outputId": "3708fc91-517e-4c83-e133-059381bde271"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "args.output_attention = True\n",
    "\n",
    "exp = Exp(args)\n",
    "\n",
    "model = exp.model\n",
    "\n",
    "# setting = 'informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0'\n",
    "path = os.path.join(args.checkpoints,setting,'checkpoint.pth')\n",
    "\n",
    "print(model.load_state_dict(torch.load(path)))\n",
    "\n",
    "df = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
    "df[args.cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDdzqm9HAk2C"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(data_loader):\n",
    "    if i!=idx:\n",
    "        continue\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    \n",
    "    dec_inp = torch.zeros_like(batch_y[:,-args.pred_len:,:]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "    \n",
    "    outputs,attn = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWef23vWAmUz",
    "outputId": "021eca83-e12f-402c-c87e-4fffa643d2f1"
   },
   "outputs": [],
   "source": [
    "attn[0].shape, attn[1].shape #, attn[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iZDH1fZgAnrl",
    "outputId": "991cae95-04a2-402d-f179-777e962f46fe"
   },
   "outputs": [],
   "source": [
    "layers = [0,1]\n",
    "distil = 'Distil' if args.distil else 'NoDistil'\n",
    "for layer in layers:\n",
    "    print(\"\\n\\n==========================\")\n",
    "    print(\"Showing attention layer\", layer)\n",
    "    print(\"==========================\\n\\n\")\n",
    "    for h in range(0,8):\n",
    "        plt.figure(figsize=[10,8])\n",
    "        plt.title('Informer, {}, attn:{} layer:{} head:{}'.format(distil, args.attn, layer, h))\n",
    "        A = attn[layer][0,h].detach().cpu().numpy()\n",
    "        ax = sns.heatmap(A, vmin=0, vmax=A.max()+0.01)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42076dbd0dc4bad15096163af3221a89f84ba4155674ba19b5bb3ffd4e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
