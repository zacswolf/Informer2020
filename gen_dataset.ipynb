{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def convert_tz(data, time_zone='US/Eastern'):\n",
    "    t = data.index.to_series(keep_tz=True)\n",
    "    t = t.dt.tz_convert(time_zone)\n",
    "    data.index = t\n",
    "    return data\n",
    "\n",
    "def write_df(data, out_file):\n",
    "    # Save flatten\n",
    "    og_cols = data.columns.copy()\n",
    "    data.columns = data.columns.to_flat_index()\n",
    "\n",
    "    data.columns = pd.Index([\"_\".join(col) for col in data.columns])\n",
    "\n",
    "    if os.path.exists(out_file):\n",
    "        # Move current file to data/old\n",
    "        data_old = \"data/old\"\n",
    "        if not os.path.exists(data_old):\n",
    "            os.makedirs(data_old)\n",
    "        new_file_name = f\"{out_file[:out_file.rfind('.')]}_{datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')}{out_file[out_file.rfind('.'):]}\"\n",
    "        os.rename(out_file, os.path.join(data_old, new_file_name))\n",
    "\n",
    "    data.to_csv(out_file)\n",
    "    data.columns = og_cols\n",
    "\n",
    "# write_df(df, \"test.csv\")\n",
    "def read_data(out_file=\"realdata.csv\"):\n",
    "    data = pd.read_csv(out_file, index_col=0)\n",
    "\n",
    "    converter = lambda col: tuple(col.split(\"_\"))\n",
    "    # ast.literal_eval\n",
    "    data.columns = data.columns.map(converter)\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    return data\n",
    "\n",
    "# df = read_data(\"test2.csv\")\n",
    "# write_df(df2, \"test2.csv\")\n",
    "\n",
    "# df = df.fillna(0).round(decimals=4)\n",
    "# df2 = df2.fillna(0).round(decimals=4)\n",
    "# print(df.head())\n",
    "# print(df2.head())\n",
    "# print(df == df2)\n",
    "# print(df.equals(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read Data From All-Data CSV (Multi Index Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = read_data(\"realdata.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering & Processing the Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_close_data(data):\n",
    "    return data.iloc[:, data.columns.get_level_values(1)=='close'] #data.xs(\"close\",level=1, axis=1)\n",
    "\n",
    "def no_premarket_after_hours(data):\n",
    "    mkt_start = datetime.time(hour=9,minute=30, tzinfo=pytz.timezone('US/Eastern'))\n",
    "    mkt_end = datetime.time(hour=15,minute=59, tzinfo=pytz.timezone('US/Eastern'))\n",
    "    data = convert_tz(data, time_zone='US/Eastern')\n",
    "    data = data.between_time(mkt_start,mkt_end)\n",
    "    data = convert_tz(data, time_zone='UTC')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df_all to normal hours\n",
    "df = no_premarket_after_hours(df_all)\n",
    "\n",
    "# Filter df_all to just Close data\n",
    "df_close = just_close_data(df)\n",
    "\n",
    "df_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_nans(data):\n",
    "    data = data.fillna(method=\"ffill\")\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def del_nans_ffill(data, thresh):\n",
    "    data = data.dropna(thresh=thresh)\n",
    "    data = ffill_nans(data)\n",
    "    return data\n",
    "\n",
    "def percentage_nans(data):\n",
    "    percent_missing = data.isnull().sum() * 100 / len(data)\n",
    "    missing_value_df = pd.DataFrame({ #'column_name': data.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "    missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "    return missing_value_df\n",
    "\n",
    "def filter_percentage_nans(data, thresh=.1):\n",
    "    thresh *= 100\n",
    "    per_nans = percentage_nans(data)\n",
    "    return data[per_nans[per_nans['percent_missing'] < thresh].index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = filter_percentage_nans(df_close)\n",
    "df_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = ffill_nans(df_close) # 138,607\n",
    "# df_processed_holes = del_nans_ffill(df_close, 3) # 91,693\n",
    "# df_close # 348,724"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df(df_close, \"data/ETT/close.csv\")\n",
    "# write_df(df_processed_holes, \"data/ETT/processed_holes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42076dbd0dc4bad15096163af3221a89f84ba4155674ba19b5bb3ffd4e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
