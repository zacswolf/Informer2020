{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import ast\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "\n",
    "# Alpha Vantage API Key https://www.alphavantage.co/support/#api-key\n",
    "ALPHA_VANTAGE_API_KEY = \"\"\n",
    "\n",
    "# Polygon\n",
    "POLYGON_API_KEY = \"\"\n",
    "\n",
    "# Alpaca\n",
    "APCA_API_BASE_URL = \"https://api.alpaca.markets\"\n",
    "APCA_API_KEY_ID = \"\"\n",
    "APCA_API_SECRET_KEY = \"\"\n",
    "\n",
    "\n",
    "equities = ['XOM','CVX', 'SHEL', 'COP', 'BP', 'PBR']\n",
    "more_equities = ['WTI']\n",
    "\n",
    "crude_oil = []#['CL=F', 'BZ=F'] # wti, brent, \n",
    "\n",
    "random = [\"TSLA\", \"AAPL\"]\n",
    "\n",
    "tickers = equities + more_equities + crude_oil\n",
    "\n",
    "\n",
    "def csv_str_to_df(decoded_content, ticker):\n",
    "    \"\"\"CSV string to df\"\"\"\n",
    "    lines = decoded_content.splitlines()\n",
    "    df = pd.DataFrame([row.split(',') for row in lines[1:]], \n",
    "                    columns=[\"date\", *lines[0].split(',')[1:]])\n",
    "\n",
    "    df = df.reset_index(drop=True).set_index('date')\n",
    "    df = pd.concat([df], axis=1, keys=[ticker])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Data From Data Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_vantage_get_ticker_data(ticker, time=\"1min\", year=1, month=1):\n",
    "    \"\"\"Function to get (ticker, year, month) data using alpha vantage's time series intraday extended API\"\"\"\n",
    "    CSV_URL = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={ticker}&interval={time}&slice=year{year}month{month}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "\n",
    "    while True:\n",
    "        with requests.Session() as s:\n",
    "            download = s.get(CSV_URL)\n",
    "            decoded_content = download.content.decode('utf-8')\n",
    "            print(f\"ticker: {ticker}, y{year} m{month}; response length: {len(decoded_content)}\")\n",
    "\n",
    "            if len(decoded_content) == 236:\n",
    "                # API too many requests\n",
    "                sleep(60)\n",
    "            elif len(decoded_content) <= 243:\n",
    "                # Token doesn't exist or something\n",
    "                print(f\"Error getting {ticker}, y{year}, m{month}. We are skipping\")\n",
    "                print(decoded_content)\n",
    "                return None\n",
    "            else:\n",
    "                return csv_str_to_df(decoded_content, ticker)\n",
    "\n",
    "\n",
    "def use_alpha_vantage(tickers, time= \"1min\", out_file=\"realdata.csv\"):\n",
    "    \"\"\"Function to get multiple full tickers data using alpha vantage's time series intraday extended API\"\"\"\n",
    "    dfs = []\n",
    "    for ticker in tickers:\n",
    "        t_dfs = []\n",
    "        for year in range(1,3):\n",
    "            for month in range(1,13):\n",
    "                df_temp = alpha_vantage_get_ticker_data(ticker, time=time, year=year, month=month)\n",
    "                if df_temp is not None:\n",
    "                    t_dfs.append(df_temp)\n",
    "\n",
    "        if len(t_dfs):\n",
    "            dfs.append(pd.concat(t_dfs, axis=0))\n",
    "        else:\n",
    "            print(f\"Skipped {ticker}.\")\n",
    "    df = pd.concat(dfs, axis=1, sort=True)\n",
    "    df.index.rename('date', inplace=True)\n",
    "\n",
    "    # Save flatten\n",
    "    og_cols = df.columns.copy()\n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.to_csv(out_file)\n",
    "    df.columns = og_cols\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def use_alpaca(tickers, alpaca, timeframe=\"1Minute\", out_file=\"realdata_alp.csv\"):\n",
    "    start = \"2017-01-01\" # This is as early as it gets\n",
    "    dfs = []\n",
    "    for ticker in tickers:\n",
    "        print(\"Getting\", ticker)\n",
    "        alpaca.get_bars()\n",
    "        df = alpaca.get_bars(ticker, timeframe, start).df\n",
    "        print(\"Recieved\", ticker)\n",
    "        df.index.name = 'date'\n",
    "        df = pd.concat([df], axis=1, keys=[ticker])\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, axis=1, sort=True)\n",
    "    df.index.rename('date', inplace=True)\n",
    "\n",
    "    # Save flatten\n",
    "    og_cols = df.columns.copy()\n",
    "    df.columns = df.columns.to_flat_index()\n",
    "    df.to_csv(out_file)\n",
    "    df.columns = og_cols\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = tradeapi.REST(key_id=APCA_API_KEY_ID, secret_key=APCA_API_SECRET_KEY, base_url=APCA_API_BASE_URL)\n",
    "account = alpaca.get_account()\n",
    "print(account.status)\n",
    "\n",
    "df = use_alpaca(tickers, alpaca, timeframe=\"1Minute\", out_file=\"realdata_alp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = use_alpha_vantage(tickers, out_file=\"realdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = \"XOM\"\n",
    "# year = 1\n",
    "# month = 1\n",
    "\n",
    "# # Minute\n",
    "# with requests.Session() as s:\n",
    "#     download = s.get(f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={'CVX'}&interval={'1min'}&slice=year{'1'}month{'1'}&apikey={ALPHA_VANTAGE_API_KEY}\")\n",
    "#     decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "#     print(decoded_content)\n",
    "\n",
    "# # Daily\n",
    "# with requests.Session() as s:\n",
    "#     ticker = \"XOM\"\n",
    "#     download = s.get(f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/2020-07-22/2020-07-22?adjusted=true&sort=asc&limit=5000&apiKey={POLYGON_API_KEY}\")\n",
    "#     decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "#     print(decoded_content)\n",
    "\n",
    "# alpha_vantage_get_ticker_data(\"CVX\")\n",
    "\n",
    "\n",
    "# symbols = \"XOM\"\n",
    "# timeframe = \"1Minute\"\n",
    "# start = \"2017-01-01\"\n",
    "# end = \"2017-01-01\"\n",
    "# data = alpaca.get_bars(symbols, timeframe, start).df\n",
    "# print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read Data From All-Data CSV (Multi Index Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(out_file=\"realdata.csv\"):\n",
    "    data = pd.read_csv(out_file, index_col=0)\n",
    "    data.columns = data.columns.map(ast.literal_eval)\n",
    "    return data\n",
    "\n",
    "df_all = read_data(\"realdata.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering & Processing the Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_close_data(data):\n",
    "    return data.xs(\"close\",level=1, axis=1)\n",
    "\n",
    "def no_premarket_after_hours():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df_all to just Close data\n",
    "df_close = just_close_data(df_all)\n",
    "df_close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_nans(df):\n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def del_nans_ffill(df, thresh):\n",
    "    df = df.dropna(thresh=thresh)\n",
    "    df = ffill_nans(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_dups = ffill_nans(df_close) # 138,607\n",
    "df_processed_holes = del_nans_ffill(df_close, 3) # 91,693\n",
    "# df_close # 348,724"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_dups.to_csv(\"data/ETT/processed_dups.csv\")\n",
    "df_processed_holes.to_csv(\"data/ETT/processed_holes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42076dbd0dc4bad15096163af3221a89f84ba4155674ba19b5bb3ffd4e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
