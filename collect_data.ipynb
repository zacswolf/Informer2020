{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Create a .env file and add your keys\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "equities = ['XOM','CVX', 'SHEL', 'COP', 'BP', 'PBR']\n",
    "more_equities = ['WTI']\n",
    "crude_oil = []#['CL=F', 'BZ=F'] # wti, brent, \n",
    "random = [\"TSLA\", \"AAPL\"]\n",
    "tickers = equities + more_equities + crude_oil\n",
    "\n",
    "\n",
    "def convert_tz(data, time_zone='US/Eastern'):\n",
    "    # print(data.index)\n",
    "    t = data.index.to_series(keep_tz=True)\n",
    "    t = t.dt.tz_convert(time_zone)\n",
    "    data.index = t\n",
    "    return data\n",
    "\n",
    "def write_df(data, out_file):\n",
    "    # Save flatten\n",
    "    og_cols = data.columns.copy()\n",
    "    data.columns = data.columns.to_flat_index()\n",
    "\n",
    "    data.columns = pd.Index([\"_\".join(col) for col in data.columns])\n",
    "\n",
    "    if os.path.exists(out_file):\n",
    "        # Move current file to data/old\n",
    "        data_old = \"data/old\"\n",
    "        if not os.path.exists(data_old):\n",
    "            os.makedirs(data_old)\n",
    "        new_file_name = f\"{out_file[:out_file.rfind('.')].replace('/','_')}_{datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')}{out_file[out_file.rfind('.'):]}\"\n",
    "        os.rename(out_file, os.path.join(data_old, new_file_name))\n",
    "\n",
    "    data.to_csv(out_file)\n",
    "    data.columns = og_cols\n",
    "\n",
    "def read_data(out_file=\"realdata.csv\"):\n",
    "    data = pd.read_csv(out_file, index_col=0)\n",
    "\n",
    "    converter = lambda col: tuple(col.split(\"_\"))\n",
    "    # ast.literal_eval\n",
    "    data.columns = data.columns.map(converter)\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Data From Data Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha Vantage API Key https://www.alphavantage.co/support/#api-key\n",
    "ALPHA_VANTAGE_API_KEY = os.environ.get(\"ALPHA_VANTAGE_API_KEY\")\n",
    "\n",
    "def add_et_tz(data):\n",
    "    \"\"\"Add ET timezone to timezone-unlabled df\"\"\"\n",
    "    t = pd.to_datetime(data.index).to_series(keep_tz=True)\n",
    "    data.index = t.dt.tz_localize('US/Eastern')\n",
    "    return data\n",
    "\n",
    "def csv_str_to_df(decoded_content, ticker):\n",
    "    \"\"\"CSV string to df\"\"\"\n",
    "    lines = decoded_content.splitlines()\n",
    "    data = pd.DataFrame([row.split(',') for row in lines[1:]], \n",
    "                    columns=[\"date\", *lines[0].split(',')[1:]])\n",
    "\n",
    "    data = data.reset_index(drop=True).set_index('date')\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "\n",
    "\n",
    "    # Add timezome -- we assume it is sent in with unlabled eastern time \n",
    "    if data.index.to_series(keep_tz=True).dt.tz is None:\n",
    "        print(\"CONVERTING TIME\")\n",
    "        data = add_et_tz(data)\n",
    "        data = convert_tz(data, time_zone=\"UTC\")\n",
    "    data = pd.concat([data], axis=1, keys=[ticker])\n",
    "    return data\n",
    "\n",
    "def alpha_vantage_get_ticker_data(ticker, time=\"1min\", year=1, month=1):\n",
    "    \"\"\"Function to get (ticker, year, month) data using alpha vantage's time series intraday extended API\"\"\"\n",
    "    CSV_URL = f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={ticker}&interval={time}&slice=year{year}month{month}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "\n",
    "    while True:\n",
    "        with requests.Session() as s:\n",
    "            download = s.get(CSV_URL)\n",
    "            decoded_content = download.content.decode('utf-8')\n",
    "            print(f\"ticker: {ticker}, y{year} m{month}; response length: {len(decoded_content)}\")\n",
    "\n",
    "            if len(decoded_content) == 236:\n",
    "                # API too many requests\n",
    "                sleep(60)\n",
    "            elif len(decoded_content) <= 243:\n",
    "                # Token doesn't exist or something\n",
    "                print(f\"Error getting {ticker}, y{year}, m{month}. We are skipping\")\n",
    "                print(decoded_content)\n",
    "                return None\n",
    "            else:\n",
    "                return csv_str_to_df(decoded_content, ticker)\n",
    "\n",
    "\n",
    "def use_alpha_vantage(tickers, time= \"1min\", out_file=\"realdata.csv\"):\n",
    "    \"\"\"Function to get multiple full tickers data using alpha vantage's time series intraday extended API\"\"\"\n",
    "    dfs = []\n",
    "    for ticker in tickers:\n",
    "        t_dfs = []\n",
    "        for year in range(1,3):\n",
    "            for month in range(1,13):\n",
    "                df_temp = alpha_vantage_get_ticker_data(ticker, time=time, year=year, month=month)\n",
    "                if df_temp is not None:\n",
    "                    t_dfs.append(df_temp)\n",
    "\n",
    "        if len(t_dfs):\n",
    "            dfs.append(pd.concat(t_dfs, axis=0))\n",
    "        else:\n",
    "            print(f\"Skipped {ticker}.\")\n",
    "    df = pd.concat(dfs, axis=1, sort=True)\n",
    "    df.index.rename('date', inplace=True)\n",
    "\n",
    "    write_df(df, out_file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca\n",
    "APCA_API_BASE_URL = os.environ.get(\"APCA_API_BASE_URL\")\n",
    "APCA_API_KEY_ID = os.environ.get(\"APCA_API_KEY_ID\")\n",
    "APCA_API_SECRET_KEY = os.environ.get(\"APCA_API_SECRET_KEY\")\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "def use_alpaca(tickers, alpaca, timeframe=\"1Minute\", out_file=\"realdata_alp.csv\", start=\"2017-01-01\"):\n",
    "    dfs = []\n",
    "    for ticker in tickers:\n",
    "        print(\"Getting\", ticker)\n",
    "        df = alpaca.get_bars(ticker, timeframe, start).df\n",
    "        print(\"Recieved\", ticker)\n",
    "        df.index.name = 'date'\n",
    "        df = pd.concat([df], axis=1, keys=[ticker])\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, axis=1, sort=True)\n",
    "    df.index.rename('date', inplace=True)\n",
    "\n",
    "    if out_file is not None:\n",
    "        write_df(df, out_file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygon\n",
    "POLYGON_API_KEY = os.environ.get(\"POLYGON_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca\n",
    "alpaca = tradeapi.REST(key_id=APCA_API_KEY_ID, secret_key=APCA_API_SECRET_KEY, base_url=APCA_API_BASE_URL)\n",
    "account = alpaca.get_account()\n",
    "print(account.status)\n",
    "\n",
    "extended_tickers = [\"TTE\", \"EQNR\", \"EOG\", \"ENB\", \"SLB\"]\n",
    "df = use_alpaca(extended_tickers, alpaca, timeframe=\"1Minute\", out_file=\"realdata_alp.csv\")\n",
    "# df = use_alpaca([], alpaca, out_file=None, start=\"2022-11-09    \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha Vantage\n",
    "df = use_alpha_vantage(tickers, out_file=\"realdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = \"XOM\"\n",
    "# year = 1\n",
    "# month = 1\n",
    "\n",
    "# # Minute\n",
    "# with requests.Session() as s:\n",
    "#     download = s.get(f\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol={'CVX'}&interval={'1min'}&slice=year{'1'}month{'1'}&apikey={ALPHA_VANTAGE_API_KEY}\")\n",
    "#     decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "#     print(decoded_content)\n",
    "\n",
    "# # Daily\n",
    "# with requests.Session() as s:\n",
    "#     ticker = \"XOM\"\n",
    "#     download = s.get(f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/2020-07-22/2020-07-22?adjusted=true&sort=asc&limit=5000&apiKey={POLYGON_API_KEY}\")\n",
    "#     decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "#     print(decoded_content)\n",
    "\n",
    "# alpha_vantage_get_ticker_data(\"CVX\")\n",
    "\n",
    "\n",
    "# symbols = \"XOM\"\n",
    "# timeframe = \"1Minute\"\n",
    "# start = \"2017-01-01\"\n",
    "# end = \"2017-01-01\"\n",
    "# data = alpaca.get_bars(symbols, timeframe, start).df\n",
    "# print(data.columns)\n",
    "# df_new.to_csv(\"tsla_aapl.csv\")\n",
    "# write_df(df, out_file=\"realdata_alp.csv\")\n",
    "# df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read Data From All-Data CSV (Multi Index Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = read_data(\"realdata.csv\")\n",
    "# df = read_data(\"tsla_aapl.csv\")\n",
    "print(df_all.head())\n",
    "print(df.head())\n",
    "print(df_all.columns)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenate two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.columns.equals(df_all.columns):\n",
    "    df_new = write_df(pd.concat([df_all,df], axis=1), \"realdata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42076dbd0dc4bad15096163af3221a89f84ba4155674ba19b5bb3ffd4e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
