{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": [
    "# Stockformer Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5GFng7v7Eq0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# if not 'Informer2020' in sys.path:\n",
    "#     sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPdt-Kwc_RRZ"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.ipynb_helpers import args_from_setting, setting_from_args, handle_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mx2dnwY9dWi"
   },
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "args.des = 'full_1h'\n",
    "\n",
    "args.model = 'mlp' # 'stockformer'\n",
    "\n",
    "args.data = 'custom' # data\n",
    "args.checkpoints = './checkpoints' # location of model checkpoints\n",
    "args.root_path = './data/ETT/' # root path of data file\n",
    "\n",
    "args.data_path = 'full_1h.csv' # data file\n",
    "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "\n",
    "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'XOM_pctchange' # target feature in S or MS task\n",
    "\n",
    "\n",
    "args.seq_len = 1 # input sequence length of Informer encoder\n",
    "args.label_len = 1 # start token length of Informer decoder\n",
    "args.pred_len = 1 # prediction sequence length\n",
    "\n",
    "#[\"XOM_close\", \"BP_close\", \"CVX_close\", \"WTI_close\"]\n",
    "#[\"XOM_open\", \"XOM_high\", \"XOM_low\", \"XOM_close\", \"XOM_volume\", \"XOM_pctchange\", \"XOM_shortsma\"]\n",
    "args.cols = [\"XOM_open\", \"XOM_close\", \"XOM_pctchange\", \"XOM_shortsma\", \n",
    "                'CVX_pctchange', 'COP_pctchange', 'BP_pctchange', 'PBR_pctchange', \n",
    "                'WTI_pctchange', 'EOG_pctchange', 'ENB_pctchange', 'SLB_pctchange',\n",
    "                ]#'C:USDSAR_pctchange'\n",
    "\n",
    "args.enc_in = len(args.cols) # encoder input size\n",
    "args.dec_in = len(args.cols) # decoder input size # TODO: Remove\n",
    "args.c_out = 1 if args.features in [\"S\", \"MS\"] else args.dec_in # output size\n",
    "\n",
    "\n",
    "args.d_model = 128 # dimension of model; this is also the dimension of the token embeddings\n",
    "args.n_heads = 8 # num of attention heads\n",
    "args.e_layers = 4 # num of encoder layers\n",
    "args.d_layers = 4 # num of decoder layers # TODO: Remove\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.5 # dropout\n",
    "args.embed = None#'timeF' # time features encoding, options:[timeF, fixed, learned, None]\n",
    "args.activation = 'gelu' # activation\n",
    "\n",
    "args.attn = 'full' # attention used in encoder, options:[prob, full]\n",
    "args.factor = 5 # probsparse attn factor; doesn't matter unless args.attn==full\n",
    "args.distil = False # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in encoder\n",
    "args.mix = False # whether to use mixed attention\n",
    "args.padding = 0 # TODO: Remove\n",
    "\n",
    "args.batch_size = 128 #64\n",
    "args.learning_rate = 0.001\n",
    "args.loss = 'mse'\n",
    "args.lradj = \"type3\" # What learning rate scheduler to use: [\"type3\", None, \"type1\"]\n",
    "args.train_epochs = 2\n",
    "args.patience = 30 # For early stopping\n",
    "\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "args.num_workers = 0\n",
    "args.itr = 1 # number of runs\n",
    "\n",
    "args.scale = True # whether to scale to mean 0, var 1\n",
    "args.inverse = False # whether to invert that scale before loss is calculated, lets keep this at False\n",
    "\n",
    "# This is for debugging to overfit\n",
    "# When True, patience doesn't matter at all and the model-state that is saved is the one after the last epoch\n",
    "# When False, the model-state that is saved is the one with the highest validation-loss and we can early stop with patience\n",
    "args.no_early_stop = True \n",
    "\n",
    "\n",
    "# Control data split from args, either a date string like \"2000-01-30\" or None (for default)\n",
    "args.date_start = \"2012-01-01\" # Train data starts on this date, default is to go back as far as possible\n",
    "args.date_end = \"2020-01-01\" # Train data starts on this date, default is to go back as far as possible\n",
    "args.date_test = \"2019-06-01\" # Test data is data after this date, default is to use ~20% of the data as test data\n",
    "\n",
    "\n",
    "\n",
    "#args.load_model_path = \"stockformer_custom_ftMS_sl16_ll4_pl1_ei12_di12_co1_iFalse_dm512_nh8_el12_dl4_df2048_atfull_fc5_ebtimeF_dtFalse_mxFalse_pretrain_full_1h_0/checkpoint-pretrain.pth\"\n",
    "\n",
    "# Code to handle gpu\n",
    "# None to use all available GPUs\n",
    "# False for not using GPUs, \n",
    "# 0 for using cuda:0, \n",
    "# \"0,1\" for using both cuda:0 and cuda:1\n",
    "handle_gpu(args, None)\n",
    "\n",
    "# TODO: Figure out what this is for\n",
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]\n",
    "\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "Exp = Exp_Informer\n",
    "\n",
    "\n",
    "# import json\n",
    "# with open(\"configs/no_hist.json\", \"w\") as f:\n",
    "#     json.dump(args, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test *args.itr* models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928tzaA2AA2g",
    "outputId": "c19f673a-02d1-4f4d-91c3-d0f25e600443"
   },
   "outputs": [],
   "source": [
    "exp = None\n",
    "setting = None\n",
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = setting_from_args(args, ii)\n",
    "    \n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "    \n",
    "    # train\n",
    "    print(f\">>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    exp.test(setting, flag=\"test\")\n",
    "    exp.test(setting, flag=\"val\")\n",
    "    exp.test(setting, flag=\"train\")\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDHF-HerAE3u"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTkluNNcyMJt",
    "outputId": "780767fe-6321-4081-e827-6701daeb375b"
   },
   "outputs": [],
   "source": [
    "# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n",
    "# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n",
    "# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n",
    "\n",
    "manual = False\n",
    "\n",
    "if manual:\n",
    "    setting = \"informer_custom_ftMS_sl256_ll64_pl16_ei1_di1_co1_iFalse_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0\"\n",
    "    args = args_from_setting(setting, args)\n",
    "    exp = Exp(args)\n",
    "\n",
    "path = os.path.join(args.checkpoints, setting, \"checkpoint.pth\")\n",
    "\n",
    "exp.predict(setting, True)\n",
    "\n",
    "# the prediction will be saved in ./results/{setting}/real_prediction.npy\n",
    "prediction = np.load(f\"./results/{setting}/real_prediction.npy\")\n",
    "\n",
    "print(prediction.shape)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(prediction[0,:,-1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNhEP_7sAgqC"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMRk8VkQ2Iko",
    "outputId": "bbf3cd10-7294-472d-e330-21e00f20963a"
   },
   "outputs": [],
   "source": [
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "tp_dict = {}\n",
    "for flag in [\"train\", \"val\", \"test\"]:\n",
    "    preds_path = f\"./results/{setting}/pred_{flag}.npy\"\n",
    "    trues_path = f\"./results/{setting}/true_{flag}.npy\"\n",
    "    dates_path = f\"./results/{setting}/date_{flag}.npy\"\n",
    "    if os.path.exists(preds_path) and os.path.exists(trues_path) and os.path.exists(dates_path):\n",
    "        tp_dict[flag] = (np.load(trues_path), np.load(preds_path), np.load(dates_path))\n",
    "        # tp_dict[flag] = list(zip(*sorted(zip(*tp_dict[flag]), key=lambda x: x[-1])))\n",
    "        s = np.argsort(tp_dict[flag][2], axis=None)\n",
    "        tp_dict[flag] = list(map(lambda x: x[s], tp_dict[flag]))\n",
    "        \n",
    "\n",
    "print(\"Open true/pred data for:\", list(tp_dict.keys()))\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "print(tp_dict[\"train\"][0].shape, tp_dict[\"val\"][0].shape, tp_dict[\"test\"][0].shape, \"\\n\\n\")\n",
    "\n",
    "for flag in tp_dict:\n",
    "    trues, preds, dates = tp_dict[flag]\n",
    "    print(f\"{flag}\\ttrues.shape: {trues.shape}, preds.shape: {preds.shape}, dates.shape: {preds.shape}\")\n",
    "    \n",
    "    MSE = np.square(np.subtract(trues,preds)).mean() \n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"against preds\", MSE, RMSE)\n",
    "\n",
    "    MSE = np.square(np.subtract(trues,np.zeros(preds.shape))).mean() \n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"against 0s\",MSE,RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "kyPuOPGAAjl3",
    "outputId": "8554f6f8-c13a-43e1-b04b-5f27823445d0"
   },
   "outputs": [],
   "source": [
    "# draw OT prediction\n",
    "for flag in tp_dict:\n",
    "    trues, preds, dates = tp_dict[flag]\n",
    "    true = trues[:,0,0]\n",
    "    pred = preds[:,0,0]\n",
    "    date = dates[:,0]\n",
    "    plt.figure(num=flag, figsize=(16,4))\n",
    "    plt.title(flag)\n",
    "    plt.plot(date, true, label='GroundTruth', linestyle=\"\",marker=\".\",markersize=4)\n",
    "    plt.plot(date, pred, label='Prediction',linestyle=\"\",marker=\".\",markersize=4)\n",
    "    # plt.scatter(range(trues.shape[0]), trues[:,0,0], marker='v', color='r', label='GroundTruth')\n",
    "    # plt.scatter(range(trues.shape[0]), preds[:,0,0], marker='^', color='m', label='Prediction')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(num=flag, figsize=(16,4))\n",
    "    plt.title(\"Diff histogram\")\n",
    "    # plt.hist(np.abs(true), bins=len(true)//6, label='Diff 0', alpha=0.5)\n",
    "    # plt.hist(np.abs(true - pred), bins=len(true)//6, label='Diff Pred', alpha=0.5)\n",
    "    plt.hist([np.abs(true), np.abs(true - pred)], bins=60, label=['Diff 0', 'Diff Pred'])\n",
    "    plt.xlabel(\"Diff Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # df = pd.concat([pd.DataFrame(a, columns=[f\"{i}\"]) for i, a in enumerate([np.abs(true - pred), np.abs(true)])], axis=1)\n",
    "\n",
    "    # # plot the data\n",
    "    # df.plot.hist(stacked=True, bins=len(true), density=True, figsize=(10, 6), grid=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "v = 0\n",
    "\n",
    "# train percent direction correct, train num excluded,\n",
    "# val percent direction correct, val num excluded,\n",
    "# test percent direction correct, test num excluded\n",
    "tracker = {} \n",
    "\n",
    "for f in np.linspace(0, .15, 301):\n",
    "    # print(\"f:\", f)\n",
    "    track = {}\n",
    "    for flag in tp_dict:\n",
    "        trues, preds = tp_dict[flag]\n",
    "        true = trues[:,0,0].copy()\n",
    "        pred = preds[:,0,0].copy()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        pred_c = pred[np.abs(pred) >= f]\n",
    "        true_c = true[np.abs(pred) >= f]\n",
    "        # print(flag, \"num excluded:\", len(pred) - len(pred_c), len(pred_c))\n",
    "        pct_correct = np.sum(np.sign(true_c) == np.sign(pred_c))/len(true_c)\n",
    "        # print(flag, pct_correct)\n",
    "        if pct_correct > m and flag=='val':\n",
    "            m = pct_correct\n",
    "            v = f\n",
    "            # print(\"set\",v)\n",
    "        \n",
    "        track[f\"{flag}_pct_correct\"] = pct_correct\n",
    "        track[f\"{flag}_pct_excluded\"] = (len(pred) - len(pred_c))/len(pred)\n",
    "\n",
    "    tracker[f] = track\n",
    "\n",
    "print(\"best f\", v)\n",
    "print(tracker[v])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iflTTl0quCoK",
    "outputId": "3708fc91-517e-4c83-e133-059381bde271"
   },
   "outputs": [],
   "source": [
    "args.output_attention = True\n",
    "\n",
    "exp = Exp(args)\n",
    "\n",
    "model = exp.model\n",
    "\n",
    "path = os.path.join(args.checkpoints,setting,'checkpoint.pth')\n",
    "\n",
    "print(model.load_state_dict(torch.load(path)))\n",
    "\n",
    "df = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
    "df[args.cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDdzqm9HAk2C"
   },
   "outputs": [],
   "source": [
    "from data_provider.data_loader import Dataset_Custom\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Data = Dataset_Custom\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
    "data_set = Data(args, flag=flag, freq=args.freq, timeenc=timeenc)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(data_loader):\n",
    "    if i!=idx:\n",
    "        continue\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "    \n",
    "    dec_inp = torch.zeros_like(batch_y[:,-args.pred_len:,:]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
    "    \n",
    "    outputs,attn = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "\n",
    "\n",
    "print(attn[0].shape, attn[1].shape) #, attn[2].shape\n",
    "\n",
    "\n",
    "\n",
    "layers = [0,1]\n",
    "distil = 'Distil' if args.distil else 'NoDistil'\n",
    "for layer in layers:\n",
    "    print(\"\\n\\n==========================\")\n",
    "    print(\"Showing attention layer\", layer)\n",
    "    print(\"==========================\\n\\n\")\n",
    "    for h in range(0, args.n_heads):\n",
    "        plt.figure(figsize=[10,8])\n",
    "        plt.title(f\"Informer, {distil}, attn:{args.attn} layer:{layer} head:{h}\")\n",
    "        A = attn[layer][0,h].detach().cpu().numpy()\n",
    "        ax = sns.heatmap(A, vmin=0, vmax=A.max()+0.01)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42076dbd0dc4bad15096163af3221a89f84ba4155674ba19b5bb3ffd4e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
